/home/ubuntu/miniconda3/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|                                                                                                                                  | 0/3495 [00:00<?, ?it/s]/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '








































































































 14%|█████████████████▏                                                                                                      | 502/3495 [03:34<21:36,  2.31it/s]










































 20%|████████████████████████                                                                                                | 699/3495 [04:59<16:34,  2.81it/s]
















 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 173/175 [00:33<00:00,  5.22it/s]
  probs = softmax(torch.Tensor(predictions))██████████████████████████████████████████████████████████████████████████████████| 175/175 [00:33<00:00,  4.90it/s]
/home/ubuntu/miniconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.
  warnings.warn(
 20%|████████████████████████                                                                                                | 699/3495 [05:33<16:34,  2.81it/s]/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
































































 29%|██████████████████████████████████                                                                                     | 1000/3495 [07:48<18:02,  2.30it/s]




















































































 40%|███████████████████████████████████████████████▌                                                                       | 1398/3495 [10:38<12:29,  2.80it/s]
















  probs = softmax(torch.Tensor(predictions))██████████████████████████████████████████████████████████████████████████████████| 175/175 [00:33<00:00,  5.85it/s]
/home/ubuntu/miniconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.
  warnings.warn(
 40%|███████████████████████████████████████████████▌                                                                       | 1398/3495 [11:13<12:29,  2.80it/s]
 40%|███████████████████████████████████████████████▌                                                                       | 1398/3495 [11:13<12:29,  2.80it/s]/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '





















 43%|███████████████████████████████████████████████████                                                                    | 1499/3495 [12:03<14:59,  2.22it/s]











































































































 57%|████████████████████████████████████████████████████████████████████▏                                                  | 2001/3495 [15:37<10:38,  2.34it/s]




















 60%|███████████████████████████████████████████████████████████████████████▍                                               | 2097/3495 [16:19<08:36,  2.71it/s]
















  probs = softmax(torch.Tensor(predictions))██████████████████████████████████████████████████████████████████████████████████| 175/175 [00:33<00:00,  5.45it/s]
/home/ubuntu/miniconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.
  warnings.warn(
 60%|███████████████████████████████████████████████████████████████████████▍                                               | 2097/3495 [16:53<08:36,  2.71it/s]
 60%|███████████████████████████████████████████████████████████████████████▍                                               | 2097/3495 [16:53<08:36,  2.71it/s]/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '





















































































 72%|█████████████████████████████████████████████████████████████████████████████████████▏                                 | 2501/3495 [19:52<07:04,  2.34it/s]































































 80%|███████████████████████████████████████████████████████████████████████████████████████████████▏                       | 2796/3495 [21:59<04:09,  2.81it/s]
















 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 173/175 [00:33<00:00,  5.21it/s]
  probs = softmax(torch.Tensor(predictions))██████████████████████████████████████████████████████████████████████████████████| 175/175 [00:33<00:00,  5.85it/s]
/home/ubuntu/miniconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.
  warnings.warn(
 80%|███████████████████████████████████████████████████████████████████████████████████████████████▏                       | 2796/3495 [22:33<04:09,  2.81it/s]/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '











































 86%|██████████████████████████████████████████████████████████████████████████████████████████████████████▏                | 3000/3495 [24:03<03:30,  2.35it/s]









































































































100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3495/3495 [27:35<00:00,  2.81it/s]
















 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████       | 165/175 [00:32<00:01,  5.19it/s]
  probs = softmax(torch.Tensor(predictions))██████████████████████████████████████████████████████████████████████████████████| 175/175 [00:33<00:00,  5.85it/s]
/home/ubuntu/miniconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.
  warnings.warn(
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3495/3495 [28:09<00:00,  2.81it/s]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3495/3495 [28:11<00:00,  2.07it/s]
/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '




























































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 976/976 [03:10<00:00,  6.00it/s]/efs/Users/Hang/LLM_FT_3GPP/LLM_FT_3GPP.py:112: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  probs = softmax(torch.Tensor(predictions))
/home/ubuntu/miniconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.
  warnings.warn(
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 976/976 [03:11<00:00,  5.09it/s]
Performance of BERT before fine-tuning on 3GPP files:
{'eval_loss': 0.8021430373191833, 'eval_f1': 0.01244663724540059, 'eval_roc_auc': 0.4709535556671789, 'eval_accuracy': 0.01244663724540059, 'eval_runtime': 199.0695, 'eval_samples_per_second': 1254.366, 'eval_steps_per_second': 4.903}
Performance of BERT after fine-tuning on 3GPP files:
{'eval_loss': 0.06464843451976776, 'eval_f1': 0.8312095023747926, 'eval_roc_auc': 0.9095765191293533, 'eval_accuracy': 0.8312095023747927, 'eval_runtime': 192.0692, 'eval_samples_per_second': 1300.084, 'eval_steps_per_second': 5.082, 'epoch': 5.0}