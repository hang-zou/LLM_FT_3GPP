/home/ubuntu/miniconda3/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|                                                                         | 0/3495 [00:00<?, ?it/s]/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '











































































































 14%|█████████                                                      | 502/3495 [03:38<21:17,  2.34it/s]










































 20%|████████████▌                                                  | 699/3495 [05:03<16:53,  2.76it/s]
















  probs = softmax(torch.Tensor(predictions))█████████████████████████| 175/175 [00:35<00:00,  5.68it/s]
/home/ubuntu/miniconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.
  warnings.warn(
 20%|████████████▌                                                  | 699/3495 [05:38<16:53,  2.76it/s]
 20%|████████████▌                                                  | 699/3495 [05:38<16:53,  2.76it/s]/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '

































































 29%|█████████████████▊                                            | 1002/3495 [07:56<17:48,  2.33it/s]






















































































 40%|████████████████████████▊                                     | 1398/3495 [10:49<12:46,  2.73it/s]
















  probs = softmax(torch.Tensor(predictions))█████████████████████████| 175/175 [00:34<00:00,  5.61it/s]
/home/ubuntu/miniconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.
  warnings.warn(
 40%|████████████████████████▊                                     | 1398/3495 [11:24<12:46,  2.73it/s]
 40%|████████████████████████▊                                     | 1398/3495 [11:24<12:46,  2.73it/s]/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '





















 43%|██████████████████████████▌                                   | 1500/3495 [12:14<14:33,  2.28it/s]












































































































 57%|███████████████████████████████████▌                          | 2002/3495 [15:53<10:40,  2.33it/s]




















 60%|█████████████████████████████████████▏                        | 2097/3495 [16:34<08:24,  2.77it/s]
















 97%|█████████████████████████████████████████████████████████████▊  | 169/175 [00:33<00:01,  5.14it/s]
  probs = softmax(torch.Tensor(predictions))█████████████████████████| 175/175 [00:34<00:00,  5.81it/s]
/home/ubuntu/miniconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.
  warnings.warn(
 60%|█████████████████████████████████████▏                        | 2097/3495 [17:09<08:24,  2.77it/s]/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '





















































































 72%|████████████████████████████████████████████▎                 | 2499/3495 [20:10<07:13,  2.30it/s]
































































 80%|█████████████████████████████████████████████████▌            | 2796/3495 [22:20<04:12,  2.77it/s]
















  probs = softmax(torch.Tensor(predictions))█████████████████████████████████████████| 175/175 [00:34<00:00,  5.78it/s]
/home/ubuntu/miniconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.
  warnings.warn(
{'eval_loss': 0.04059942066669464, 'eval_f1': 0.8992837958818263, 'eval_roc_auc': 0.9460448906509784, 'eval_accuracy': 0.8992837958818263, 'eval_runtime': 34.8186, 'eval_samples_per_second': 1283.223, 'eval_steps_per_second': 5.026, 'epoch': 4.0}
 80%|█████████████████████████████████████████████████▌            | 2796/3495 [22:54<04:12,  2.77it/s]                /home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '











































 86%|█████████████████████████████████████████████████████▏        | 2996/3495 [24:28<03:37,  2.29it/s]











































































































100%|██████████████████████████████████████████████████████████████| 3495/3495 [28:04<00:00,  2.67it/s]
















  probs = softmax(torch.Tensor(predictions))█████████████████████████████████████████| 175/175 [00:34<00:00,  5.41it/s]
/home/ubuntu/miniconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.
  warnings.warn(
{'eval_loss': 0.03983628377318382, 'eval_f1': 0.9025738585496866, 'eval_roc_auc': 0.9478074242230465, 'eval_accuracy': 0.9025738585496866, 'eval_runtime': 34.8433, 'eval_samples_per_second': 1282.313, 'eval_steps_per_second': 5.022, 'epoch': 5.0}
100%|██████████████████████████████████████████████████████████████| 3495/3495 [28:39<00:00,  2.67it/s]
100%|██████████████████████████████████████████████████████████████| 3495/3495 [28:46<00:00,  2.02it/s]
/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '































































































100%|████████████████████████████████████████████████████████████████████████████████| 976/976 [03:11<00:00,  5.99it/s]/efs/Users/Hang/LLM_FT_3GPP/LLM_FT_3GPP.py:112: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  probs = softmax(torch.Tensor(predictions))
/home/ubuntu/miniconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.
  warnings.warn(
Performance of BERT before fine-tuning on 3GPP files:
{'eval_loss': 0.7691028118133545, 'eval_f1': 0.027115888284622715, 'eval_roc_auc': 0.4788120830096193, 'eval_accuracy': 0.027115888284622715, 'eval_runtime': 205.208, 'eval_samples_per_second': 1216.843, 'eval_steps_per_second': 4.756}
Performance of BERT after fine-tuning on 3GPP files:
{'eval_loss': 0.06423239409923553, 'eval_f1': 0.8344493123913721, 'eval_roc_auc': 0.911312131638235, 'eval_accuracy': 0.8344493123913722, 'eval_runtime': 193.2046, 'eval_samples_per_second': 1292.443, 'eval_steps_per_second': 5.052, 'epoch': 5.0}
100%|████████████████████████████████████████████████████████████████████████████████| 976/976 [03:13<00:00,  5.06it/s]