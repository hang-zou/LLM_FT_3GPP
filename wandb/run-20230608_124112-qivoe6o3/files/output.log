/home/ubuntu/miniconda3/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|                                                                                              | 0/2097 [00:00<?, ?it/s]/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '











































































































 24%|████████████████████▏                                                               | 503/2097 [03:36<11:30,  2.31it/s]









































 33%|████████████████████████████                                                        | 699/2097 [05:00<08:29,  2.75it/s]

















  probs = softmax(torch.Tensor(predictions))██████████████████████████████████████████████| 175/175 [00:35<00:00,  5.46it/s]
/home/ubuntu/miniconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.
  warnings.warn(
 33%|████████████████████████████                                                        | 699/2097 [05:36<08:29,  2.75it/s]
 33%|████████████████████████████                                                        | 699/2097 [05:36<08:29,  2.75it/s]/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
































































 48%|███████████████████████████████████████▌                                           | 1000/2097 [07:46<07:49,  2.33it/s]





















































































 67%|███████████████████████████████████████████████████████▎                           | 1398/2097 [10:37<04:10,  2.79it/s]
















 97%|██████████████████████████████████████████████████████████████████████████████████████████████████████   | 170/175 [00:33<00:00,  5.19it/s]
  probs = softmax(torch.Tensor(predictions))██████████████████████████████████████████████████████████████████| 175/175 [00:34<00:00,  5.83it/s]
/home/ubuntu/miniconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.
  warnings.warn(
 67%|███████████████████████████████████████████████████████▎                           | 1398/2097 [11:12<04:10,  2.79it/s]                    /home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '





















 71%|███████████████████████████████████████████████████████████▎                       | 1498/2097 [11:57<04:22,  2.28it/s]











































































































 95%|███████████████████████████████████████████████████████████████████████████████    | 1998/2097 [15:31<00:42,  2.34it/s]





















100%|███████████████████████████████████████████████████████████████████████████████████| 2097/2097 [16:14<00:00,  2.76it/s]
















 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████▌  | 171/175 [00:33<00:00,  5.09it/s]
  probs = softmax(torch.Tensor(predictions))██████████████████████████████████████████████████████████████████| 175/175 [00:34<00:00,  5.80it/s]
/home/ubuntu/miniconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.
  warnings.warn(
100%|███████████████████████████████████████████████████████████████████████████████████| 2097/2097 [16:49<00:00,  2.76it/s]
100%|███████████████████████████████████████████████████████████████████████████████████| 2097/2097 [16:51<00:00,  2.07it/s]
/home/ubuntu/miniconda3/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '






























































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 976/976 [03:10<00:00,  6.00it/s]/efs/Users/Hang/LLM_FT_3GPP/LLM_FT_3GPP.py:112: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  probs = softmax(torch.Tensor(predictions))
/home/ubuntu/miniconda3/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.
  warnings.warn(
Performance of BERT before fine-tuning on 3GPP files:
{'eval_loss': 0.742583155632019, 'eval_f1': 0.026951695193547613, 'eval_roc_auc': 0.47872412242511475, 'eval_accuracy': 0.026951695193547613, 'eval_runtime': 204.3787, 'eval_samples_per_second': 1221.781, 'eval_steps_per_second': 4.775}
Performance of BERT after fine-tuning on 3GPP files:
{'eval_loss': 0.06985998898744583, 'eval_f1': 0.8188269404820069, 'eval_roc_auc': 0.9029430038296467, 'eval_accuracy': 0.8188269404820069, 'eval_runtime': 192.4366, 'eval_samples_per_second': 1297.601, 'eval_steps_per_second': 5.072, 'epoch': 3.0}
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 976/976 [03:12<00:00,  5.08it/s]